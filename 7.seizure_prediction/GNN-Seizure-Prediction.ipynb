{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af6ac4e-fd64-4a46-90df-dcca726d464d",
   "metadata": {},
   "source": [
    "# 0. Prepare the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "df9404bf-d1b1-4770-826b-1431e1380803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (3.11.13)\n",
      "Requirement already satisfied: fsspec in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (3.1.5)\n",
      "Requirement already satisfied: numpy in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (6.1.1)\n",
      "Requirement already satisfied: pyparsing in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from requests->torch-geometric) (2024.12.14)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/wanhong-huang/miniconda3/envs/embc2025/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "# 1. install pytorch\n",
    "  ## Please follow instruction in https://pytorch.org/get-started/locally/\n",
    "\n",
    "# 2. install torch-geometric\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8903c030-e46e-48a6-b236-570bbf1f3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler, WeightedRandomSampler\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66a87e-b27e-4e1b-bef1-bda347b2e311",
   "metadata": {},
   "source": [
    "# 1. Prepare data structure and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4231b758-e3d4-428c-8e47-b0733a870cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_records_base_path = \"../data/serialized_tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49c9cee-0971-4436-8418-d391450812de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntaxTreeNode:\n",
    "    def __init__(self, value, left=None, right=None):\n",
    "        self.value = value  # Tuple of 6 values\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    @property\n",
    "    def children(self):\n",
    "        return [self.left, self.right]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"SyntaxTreeNode(value={self.value}, left={self.left}, right={self.right})\"\n",
    "\n",
    "\n",
    "def deserialize_tree(tree_str):\n",
    "    tokens = tree_str.split()\n",
    "    index = 0\n",
    "\n",
    "    def _deserialize_helper():\n",
    "        nonlocal index\n",
    "        if index >= len(tokens):\n",
    "            return None\n",
    "\n",
    "        if tokens[index] == \"#\":\n",
    "            index += 1\n",
    "            return None\n",
    "\n",
    "        # Extract the 6 values for the current node\n",
    "        value = (\n",
    "            int(tokens[index]),     # std::get<0>\n",
    "            int(tokens[index + 1]), # std::get<1>\n",
    "            int(tokens[index + 2]), # std::get<2>\n",
    "            int(tokens[index + 3]), # std::get<3>\n",
    "            float(tokens[index + 4]), # std::get<4>\n",
    "            int(tokens[index + 5])  # std::get<5>\n",
    "        )\n",
    "        index += 6\n",
    "\n",
    "        # Recursively deserialize left and right children\n",
    "        left = _deserialize_helper()\n",
    "        right = _deserialize_helper()\n",
    "\n",
    "        return SyntaxTreeNode(value, left, right)\n",
    "\n",
    "    return _deserialize_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7f1008-e32d-4e6f-9ff3-91400e0faa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_graph(root):\n",
    "    \"\"\"\n",
    "    Convert a SyntaxTreeNode to a PyTorch Geometric graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = []\n",
    "    edges = []\n",
    "    node_id_map = {}\n",
    "\n",
    "    def dfs(node, parent_id=None):\n",
    "        if (node is None):\n",
    "            return\n",
    "            \n",
    "        # Assign a unique ID to the node\n",
    "        node_id = len(nodes)\n",
    "        node_id_map[node] = node_id\n",
    "        nodes.append(node)\n",
    "\n",
    "        # Add edge from parent to current node\n",
    "        if parent_id is not None:\n",
    "            edges.append((parent_id, node_id))\n",
    "\n",
    "        # Recursively process children\n",
    "        for child in node.children:\n",
    "            dfs(child, node_id)\n",
    "\n",
    "    dfs(root)\n",
    "    \n",
    "    x = []\n",
    "    for node in nodes:\n",
    "        # Assume node.features is an order-6 tuple\n",
    "        features = node.value\n",
    "\n",
    "        # Separate dimensions\n",
    "        feature_0 = (int)(features[0]) + 1\n",
    "        feature_0 = 0 if feature_0 == 65536 else feature_0\n",
    "        \n",
    "        feature_1 = (int)(features[1]) + 1\n",
    "        feature_1 = 0 if feature_1 == 65536 else feature_1\n",
    "        \n",
    "        feature_2 = (int)(features[2]) + 1\n",
    "        feature_2 = 0 if feature_2 == 65536 else feature_2\n",
    "\n",
    "        feature_5 = (int)(features[5]) + 1\n",
    "        feature_5 = 0 if feature_5 == 65536 else feature_5\n",
    "   \n",
    "        possibility = features[4]\n",
    "        \n",
    "        \n",
    "        # Concatenate all features into a single vector\n",
    "        node_features = torch.tensor([possibility, feature_0, feature_1, feature_2, feature_5], dtype = torch.float)\n",
    "        x.append(node_features)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # Edge indices\n",
    "\n",
    "    return Data(\n",
    "        x=torch.stack(x),  # Node feature matrix\n",
    "        edge_index=edge_index # Edge index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60cf768e-6745-4780-ac0b-03278288e83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyntaxTreeNode(value=(1, 2, 3, 4, 5.0, 6), left=SyntaxTreeNode(value=(7, 8, 9, 10, 11.0, 12), left=None, right=None), right=None)\n",
      "Data(x=[2, 5], edge_index=[2, 1])\n",
      "Node features: tensor([[ 5.,  2.,  3.,  4.,  7.],\n",
      "        [11.,  8.,  9., 10., 13.]])\n",
      "Edge index: tensor([[0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "# Example serialized tree string\n",
    "tree_str = \"1 2 3 4 5.0 6 7 8 9 10 11.0 12 # # #\"\n",
    "\n",
    "# Deserialize the tree\n",
    "root = deserialize_tree(tree_str)\n",
    "print(root)\n",
    "# Convert the tree to a graph\n",
    "graph = tree_to_graph(root)\n",
    "\n",
    "# Print the graph\n",
    "print(graph)\n",
    "print(\"Node features:\", graph.x)\n",
    "print(\"Edge index:\", graph.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a29970-429b-4d90-844c-76c874ecddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "class TreeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, area_types):\n",
    "        super(TreeDataset, self).__init__()\n",
    "        files = []\n",
    "        labels = []\n",
    "        self.label_map = {\n",
    "            'normal': 0,\n",
    "            'seizure': 1,\n",
    "            'pre-epileptic': 2\n",
    "        }\n",
    "        \n",
    "        for area_type in area_types:\n",
    "            dataset_base_path = os.path.join(tree_records_base_path, area_type)\n",
    "            files_this_area_type = ([os.path.join(dataset_base_path, file) for file in os.listdir(dataset_base_path)])\n",
    "            files += files_this_area_type\n",
    "            labels += [self.label_map[area_type]] * len(files_this_area_type)\n",
    "            print(f'Add {len(files_this_area_type)} for category {area_type}')\n",
    "            \n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        assert(len(self.files) == len(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def __getitem__(self, idx):\n",
    "        if(idx >= len(self.files)):\n",
    "            raise ValueError(f'idx = {idx} >= total amount of files = {len(self.files)}')\n",
    "        file = self.files[idx]\n",
    "        with open(file, \"r\") as f:\n",
    "            serialized_tree = f.read().strip()\n",
    "        root = deserialize_tree(serialized_tree)\n",
    "        graph = tree_to_graph(root)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return {\"graph\": graph, \"label\":label}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231525d4-f395-4666-829e-fbfef002f5ed",
   "metadata": {},
   "source": [
    "# 2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ed71f-fcb0-457f-8a9a-cc6bec2a5154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f2f73b-35d3-4267-8abb-cb682f000def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add 565638 for category normal\n",
      "Add 28084 for category seizure\n",
      "Add 152313 for category pre-epileptic\n"
     ]
    }
   ],
   "source": [
    "dataset_types = [\"normal\", \"seizure\", \"pre-epileptic\"]\n",
    "\n",
    "dataset = TreeDataset(dataset_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f82139-f248-4d4f-9829-fccdef024a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9583b3-e768-4871-ae51-10c819de65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 596828\n",
      "Validation size: 74603\n",
      "Test size: 74604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "# Assuming 'dataset' is an instance of TreeDataset\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    list(range(len(dataset))), \n",
    "    test_size=0.2, \n",
    "    stratify=dataset.labels\n",
    ")\n",
    "\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, \n",
    "    test_size=0.5, \n",
    "    stratify=[dataset.labels[i] for i in temp_idx]  # This is fine since temp_idx contains the original indices\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "test_subset = torch.utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "\n",
    "# Now we calculate the weights based on the train_subset (not the full dataset)\n",
    "train_labels = [dataset.labels[i] for i in train_idx]\n",
    "\n",
    "# Calculate class counts for the training set\n",
    "class_counts = [0, 0, 0]  # For normal, seizure, pre-epileptic\n",
    "for label in train_labels:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "total_samples = len(train_labels)\n",
    "class_weights = [total_samples / count for count in class_counts]\n",
    "\n",
    "# Calculate sample weights for the training set\n",
    "sample_weights = [class_weights[label] for label in train_labels]\n",
    "\n",
    "# Create the sampler for the training set\n",
    "train_sampler = WeightedRandomSampler(sample_weights, len(train_labels), replacement=True)\n",
    "\n",
    "\n",
    "# Print sizes to confirm\n",
    "print(f\"Train size: {len(train_subset)}\")\n",
    "print(f\"Validation size: {len(val_subset)}\")\n",
    "print(f\"Test size: {len(test_subset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ca43ef8-daf1-4c59-b828-535c6322a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to batch torch_geometric.data.Data objects.\n",
    "    Args:\n",
    "        batch: List of dictionaries containing \"graph\" and \"label\".\n",
    "    Returns:\n",
    "        Batched graphs and labels.\n",
    "    \"\"\"\n",
    "    graphs = [item[\"graph\"] for item in batch]\n",
    "    labels = [item[\"label\"] for item in batch]\n",
    "    \n",
    "    # Batch graphs using PyTorch Geometric's Batch class\n",
    "    batched_graphs = Batch.from_data_list(graphs)\n",
    "    \n",
    "    # Stack labels into a tensor\n",
    "    batched_labels = torch.stack(labels)\n",
    "    \n",
    "    return batched_graphs, batched_labels\n",
    "    \n",
    "# Create DataLoader for the training set with WeightedRandomSampler\n",
    "train_loader = DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=32,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=custom_collate  # Use custom collate function\n",
    ")\n",
    "\n",
    "# Create DataLoader for the validation and test sets without any sampling (just shuffle them)\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate  # Use custom collate function\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_subset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate  # Use custom collate function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d039cc-a134-47f5-925e-505446d986e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d68447-949b-4534-aa83-c8ef0b313d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the count of each label in the dataset\n",
    "def print_label_counts(loader, dataset_type=\"train\"):\n",
    "    # Initialize label counts\n",
    "    label_counts = {0: 0, 1: 0, 2: 0}  # Assuming 3 classes (normal=0, seizure=1, pre-epileptic=2)\n",
    "    \n",
    "    # Iterate over the dataset in the loader to count each label\n",
    "    for data, labels in tqdm(loader):\n",
    "        for label in labels:\n",
    "            label_counts[label.item()] += 1\n",
    "    print(f\"{dataset_type} set label counts:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "    print()\n",
    "\n",
    "# Print label counts for train, validation, and test loaders\n",
    "print_label_counts(train_loader, dataset_type=\"train\")\n",
    "print_label_counts(val_loader, dataset_type=\"validation\")\n",
    "print_label_counts(test_loader, dataset_type=\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec648e3-8573-47f7-b422-b91b47d351b8",
   "metadata": {},
   "source": [
    "# 3. Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49638cbb-6667-4ace-a432-ffe242f21d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d6c52a2-8030-402a-b492-e5546a8a9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TreeGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes = 3):\n",
    "        super(TreeGNN, self).__init__()\n",
    "        # Define embedding layers\n",
    "        self.dim0_embedding = nn.Embedding(num_embeddings=96, embedding_dim=32)\n",
    "        self.dim1_embedding = nn.Embedding(num_embeddings=96, embedding_dim=32)\n",
    "        self.dim2_embedding = nn.Embedding(num_embeddings=96, embedding_dim=32)\n",
    "        self.dim5_embedding = nn.Embedding(num_embeddings=182, embedding_dim=32)\n",
    "\n",
    "        # Define GNN layers\n",
    "        self.conv1 = GCNConv(129, hidden_dim)  # Input size: 1 + 32*4 = 129\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Separate features\n",
    "        possibility = x[:, 0].unsqueeze(1)  # Shape: [num_nodes, 1]\n",
    "        dim0 = x[:, 1].long()\n",
    "        dim1 = x[:, 2].long()\n",
    "        dim2 = x[:, 3].long()\n",
    "        dim5 = x[:, 4].long()\n",
    "\n",
    "        # Embed categorical features\n",
    "        dim0_embedded = self.dim0_embedding(dim0)  # Shape: [num_nodes, 16]\n",
    "        dim1_embedded = self.dim1_embedding(dim1)  # Shape: [num_nodes, 16]\n",
    "        dim2_embedded = self.dim2_embedding(dim2)  # Shape: [num_nodes, 16]\n",
    "        dim5_embedded = self.dim5_embedding(dim5)  # Shape: [num_nodes, 16]\n",
    "\n",
    "        # Concatenate all features\n",
    "        x = torch.cat([possibility, dim0_embedded, dim1_embedded, dim2_embedded, dim5_embedded], dim=1)\n",
    "        # Pass through GNN layers\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))  # Shape: [num_nodes, hidden_dim]\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))          # Shape: [num_nodes, output_dim]\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features into graph-level features\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "774e4192-5b01-4964-9bc4-e5ccb9637755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TreeGNN(hidden_dim=128,  num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df78300a-a19b-421e-a762-41e7877d0b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 50/18651 [00:02<15:44, 19.69it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class_weights = torch.tensor([1.0, 2.0, 1.0])  # Higher weight for class 1 (seizure)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Cross-Entropy Loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "def calculate_metrics(conf_matrix):\n",
    "    \"\"\"\n",
    "    Calculate accuracy, TPR, FPR, TNR, FNR, F1, and F2 from a confusion matrix.\n",
    "    Args:\n",
    "        conf_matrix: Confusion matrix (3x3 for 3 classes).\n",
    "    Returns:\n",
    "        Dictionary of metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # True Positives (diagonal of the confusion matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    \n",
    "    # False Positives (sum of columns minus diagonal)\n",
    "    FP = np.sum(conf_matrix, axis=0) - TP\n",
    "    \n",
    "    # False Negatives (sum of rows minus diagonal)\n",
    "    FN = np.sum(conf_matrix, axis=1) - TP\n",
    "    \n",
    "    # True Negatives (total samples minus TP, FP, FN)\n",
    "    TN = np.sum(conf_matrix) - (TP + FP + FN)\n",
    "    \n",
    "    # Accuracy\n",
    "    metrics[\"accuracy\"] = np.sum(TP) / np.sum(conf_matrix)\n",
    "    \n",
    "    # True Positive Rate (Recall)\n",
    "    metrics[\"TPR\"] = np.divide(TP, TP + FN, where=(TP + FN) != 0)\n",
    "    \n",
    "    # False Positive Rate\n",
    "    metrics[\"FPR\"] = np.divide(FP, FP + TN, where=(FP + TN) != 0)\n",
    "    \n",
    "    # True Negative Rate\n",
    "    metrics[\"TNR\"] = np.divide(TN, TN + FP, where=(TN + FP) != 0)\n",
    "    \n",
    "    # False Negative Rate\n",
    "    metrics[\"FNR\"] = np.divide(FN, TP + FN, where=(TP + FN) != 0)\n",
    "    \n",
    "    # Precision\n",
    "    precision = np.divide(TP, TP + FP, where=(TP + FP) != 0)\n",
    "    \n",
    "    # F1 Score\n",
    "    metrics[\"F1\"] = np.divide(2 * (precision * metrics[\"TPR\"]), (precision + metrics[\"TPR\"]), where=(precision + metrics[\"TPR\"]) != 0)\n",
    "    \n",
    "    # F2 Score\n",
    "    metrics[\"F2\"] = np.divide(5 * (precision * metrics[\"TPR\"]), (4 * precision + metrics[\"TPR\"]), where=(4 * precision + metrics[\"TPR\"]) != 0)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: get predictions\n",
    "        graphs, labels = batch['graph'], batch['label']\n",
    "        output = model(graphs.x, graphs.edge_index, graphs.batch)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Store predictions and labels for metrics\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    train_metrics = calculate_metrics(train_conf_matrix)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
    "    print(f\"Training Metrics: {train_metrics}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            graphs, labels = batch['graph'], batch['label']\n",
    "            output = model(graphs.x, graphs.edge_index, graphs.batch)\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Store predictions and labels for metrics\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_conf_matrix = confusion_matrix(val_labels, val_preds)\n",
    "    val_metrics = calculate_metrics(val_conf_matrix)\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Metrics: {val_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bec31a-0fe3-4dae-8aa7-2c88b758cf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "336a57f0-5807-43c0-846f-5a799d398c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'augment_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create two views of the same tree (e.g., by random masking)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m view1 \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# Original graph\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m view2 \u001b[38;5;241m=\u001b[39m \u001b[43maugment_tree\u001b[49m(batch)  \u001b[38;5;66;03m# Augmented graph\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Encode both views\u001b[39;00m\n\u001b[1;32m     36\u001b[0m z1 \u001b[38;5;241m=\u001b[39m model(view1\u001b[38;5;241m.\u001b[39mx, view1\u001b[38;5;241m.\u001b[39medge_index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'augment_tree' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TreeContrastiveModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim):\n",
    "        super(TreeContrastiveModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long))  # Global pooling\n",
    "\n",
    "# Contrastive loss (NT-Xent)\n",
    "def contrastive_loss(z1, z2, temperature=0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    logits = torch.matmul(z1, z2.T) / temperature\n",
    "    labels = torch.arange(z1.size(0)).to(z1.device)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "# Example usage\n",
    "model = TreeContrastiveModel(input_dim=6, hidden_dim=16, embedding_dim=8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        # Create two views of the same tree (e.g., by random masking)\n",
    "        view1 = batch  # Original graph\n",
    "        view2 = augment_tree(batch)  # Augmented graph\n",
    "        # Encode both views\n",
    "        z1 = model(view1.x, view1.edge_index)\n",
    "        z2 = model(view2.x, view2.edge_index)\n",
    "        # Compute contrastive loss\n",
    "        loss = contrastive_loss(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5af209-e81c-4601-a33f-9358d48f266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class VGAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim):\n",
    "        super(VGAE, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv_mu = GCNConv(hidden_dim, embedding_dim)\n",
    "        self.conv_logvar = GCNConv(hidden_dim, embedding_dim)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logvar = self.conv_logvar(x, edge_index)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, batch):\n",
    "        adj_reconstructed = []\n",
    "        for graph_idx in torch.unique(batch):\n",
    "            graph_mask = (batch == graph_idx)\n",
    "            z_graph = z[graph_mask]\n",
    "            if z_graph.size(0) == 0:  # Skip empty graphs\n",
    "                continue\n",
    "            adj_graph = torch.sigmoid(torch.matmul(z_graph, z_graph.t()))\n",
    "            adj_reconstructed.append(adj_graph)\n",
    "        return adj_reconstructed\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        mu, logvar = self.encode(x, edge_index)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "# Loss function\n",
    "def vgae_loss(z, mu, logvar, edge_index, batch, kl_weight):\n",
    "    adj_reconstructed = decode(z, batch)\n",
    "    \n",
    "    recon_loss = 0\n",
    "    for graph_idx in torch.unique(batch):\n",
    "        graph_mask = (batch == graph_idx)\n",
    "        num_nodes = graph_mask.sum().item()\n",
    "        \n",
    "        # Filter edges for the current graph\n",
    "        edge_mask = (batch[edge_index[0]] == graph_idx) & (batch[edge_index[1]] == graph_idx)\n",
    "        edge_index_graph = edge_index[:, edge_mask]\n",
    "        \n",
    "        # Adjust edge indices to be relative to the current graph\n",
    "        edge_index_graph = edge_index_graph - edge_index_graph.min()\n",
    "        \n",
    "        # Create the true adjacency matrix\n",
    "        adj_true = torch.zeros(num_nodes, num_nodes).to(z.device)\n",
    "        adj_true[edge_index_graph[0], edge_index_graph[1]] = 1\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        recon_loss += F.binary_cross_entropy(adj_reconstructed[graph_idx], adj_true)\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss +  kl_loss\n",
    "\n",
    "def kl_annealing(epoch, max_epochs):\n",
    "    return min(epoch / max_epochs, 1.0)  # Linear annealing\n",
    "\n",
    "\n",
    "model = VGAE(input_dim=6, hidden_dim=256, embedding_dim=128)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "max_epochs = 100\n",
    "for epoch in range(max_epochs):\n",
    "    kl_weight = kl_annealing(epoch, max_epochs)\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        z, mu, logvar = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = vgae_loss(z, mu, logvar, batch.edge_index, batch.batch, kl_weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}, KL Weight: {kl_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb603f-ee0f-4d74-a815-2bbe366f9de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
