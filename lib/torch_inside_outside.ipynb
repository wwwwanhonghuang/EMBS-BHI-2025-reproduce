{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ce440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d790201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKYParser(nn.Module):\n",
    "    def __init__(self, T, NT, MAX_SEQ_LENGTH):\n",
    "        super(CKYParser).__init__()\n",
    "        self.T = T\n",
    "        self.NT = NT\n",
    "        self.S = T + NT\n",
    "        self.MAX_SEQ_LENGTH = MAX_SEQ_LENGTH\n",
    "        self.CKY_table = torch.zeros((self.S, MAX_SEQ_LENGTH, MAX_SEQ_LENGTH))\n",
    "        \n",
    "    def forward(self, grammar, sequence):\n",
    "        S, l = self.S, len(sequence)\n",
    "        self.CKY_table.fill_(-float('inf'))  # Reset with -inf (log-space)\n",
    "        \n",
    "        # ===== Span 1: Terminal Rules (A → word) =====\n",
    "        word_indices = sequence  # shape: (l,)\n",
    "        span1_probs = grammar[self.T:, word_indices, 0]  # shape: (NT, l)\n",
    "        diag_indices = torch.arange(l)\n",
    "        self.CKY_table[self.T:, diag_indices, diag_indices] = span1_probs\n",
    "\n",
    "        # ===== Spans 2 to l: Vectorized CKY =====\n",
    "        # Create a buffer to store intermediate split probabilities\n",
    "        Buffer = torch.full((S, S, S, l, l), -float('inf'), device=self.CKY_table.device)\n",
    "\n",
    "        # Generate all (i, j, k) triplets where i < k < j\n",
    "        for span in range(2, l + 1):\n",
    "            i = torch.arange(l - span + 1)\n",
    "            j = i + span  # j = i + span - 1 (adjusted for 0-based indexing)\n",
    "            \n",
    "            # Generate all valid k where i < k < j\n",
    "            k = (i.unsqueeze(1) + torch.arange(1, span).unsqueeze(0))  # shape: (i, k)\n",
    "            k = k.clamp(max=l - 1)  # Ensure k stays within bounds\n",
    "            \n",
    "            # Left subtree: s[i..k] → B\n",
    "            left_probs = self.CKY_table[:, i.unsqueeze(1), k]  # [S, i, k]\n",
    "            \n",
    "            # Right subtree: s[k+1..j] → C\n",
    "            k_plus_1 = (k + 1).clamp(max=l - 1)  # Prevent k+1 from exceeding l-1\n",
    "            right_probs = self.CKY_table[:, k_plus_1, j.unsqueeze(1)]  # [S, k, j]\n",
    "            \n",
    "            # Combine: P(B) + P(C) + P(A → B C)\n",
    "            prob = (\n",
    "                left_probs.unsqueeze(2) +  # [S, i, k, 1]\n",
    "                right_probs.unsqueeze(1) +  # [S, 1, k, j]\n",
    "                grammar.unsqueeze(-1).unsqueeze(-1)  # [S, S, S, 1, 1]\n",
    "            )\n",
    "            \n",
    "            # Aggregate over (B, C) for each A\n",
    "            self.CKY_table[self.T:, i, j] = torch.logsumexp(\n",
    "                prob[self.T:], dim=(1, 2, 3)  # [NT, i, j]\n",
    "            )\n",
    "\n",
    "        return self.CKY_table\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dca5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CKYParser(34, 16, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb850a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.forward(torch.zeros((50, 50, 50)), torch.zeros((512), dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dbae26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embc2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
